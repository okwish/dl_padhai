{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3858f5",
   "metadata": {},
   "source": [
    "**gpu in colab**  \n",
    "we are running on a cloud device which has GPU available.  \n",
    "can add GPU:  \n",
    "edit - notebook setting - hardware accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedab51",
   "metadata": {},
   "source": [
    "Pytorch framework. - programming style, and a set of libraries to do stuff.\n",
    "\n",
    "numpy doesn't make use of the GPU.. but pytorch enables it(optimally run the code in GPU).  \n",
    "\n",
    "GPU => thousands of smaller cores(special purpose), as opposed to a few large cores in CPU.  \n",
    "\n",
    "- efficient execution(tensor computation) on GPUs(eq to what numpy does to normal python)\n",
    "- Autograd - BackProp in a functional manner  \n",
    "    we can just write relations between tensors functionally and differentiate with them  \n",
    "    torch does that for us - tracking a computional graph as we are defining relations\n",
    "\n",
    "**essence of things done in DL:** basically taking an input(a tensor) and repeatedly modifying them (linear combination, activation function,.. ), finally a loss fn. - then we want the differetial of the loss fn wrt all parameters      \n",
    "< something like that can be defined and automatic diff can be done using pytorch. >\n",
    "\n",
    "forward and backward pass - efficiently done with GPU acceln.  \n",
    "reln b/w tensors and differentiating through them.  \n",
    "forward formulas on tensors - also differentiation formulas on tensors\n",
    "\n",
    "gradient descent on loss surface  \n",
    "loss function on parameters; derivative loss function wrt each parameter..   \n",
    "\n",
    "**cuda** - native libraries to accelerate on nvidia GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a6b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d4e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e798b135",
   "metadata": {},
   "source": [
    "### Torch Tensors  \n",
    "\n",
    "**ndarrays:numpy :: tensors:torch**  \n",
    "**tensor is the basic type in torch**\n",
    "\n",
    "generalisations of vectors, matrices... (indexed numbers.)   \n",
    "\n",
    "program - tensor is a 'class-type'.   \n",
    "class abstraction of a tensor.   \n",
    "\n",
    "**torch can be thought of as: extra differentiation capabilities over numpy-like-stuff-for-gpu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55029955",
   "metadata": {},
   "source": [
    "#### initialising tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117532b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5760, 0.8222],\n",
       "        [0.6528, 0.1685],\n",
       "        [0.6972, 0.8428]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,2)\n",
    "\n",
    "torch.zeros(3,2)\n",
    "\n",
    "torch.rand(3,2)\n",
    "\n",
    "# notice - dimension is not specified with another list like in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649ae8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = torch.empty(3,2) #empty tensor\n",
    "#values will be what that is already existing in the memory at that point\n",
    "\n",
    "Y2 = torch.zeros_like(X2) #zeros with dim of arg.\n",
    "\n",
    "#this \"like\" thing with other fns are also there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65daf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,1,steps=5) #5 steps b/w 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ed1ea2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2],\n",
    "              [3,4],\n",
    "              [5,6]])\n",
    "\n",
    "#can use with a list also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863274a",
   "metadata": {},
   "source": [
    "torch.tensor always copies the data. For example, torch.tensor(x) is equivalent to x.clone().detach()  \n",
    "this is not a \"bridge\" (will see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4446a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f0264fe",
   "metadata": {},
   "source": [
    "### Device, Cuda\n",
    "\n",
    "GPU\n",
    "\n",
    "cuda - language extension by nvidia to support programming GPUs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f507b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624d0ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device() \n",
    "# there is a \"current device\"\n",
    "# device-0 is 'current' by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2c1a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8313b863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1070'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbca81a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7ff4c40ed1c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0) # returns a device_object\n",
    "# the device_object is used after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb66a6f",
   "metadata": {},
   "source": [
    "torch.cuda.device() - cuda stuff. expects a cuda device.    \n",
    "torch.device() - general stuff. cpu, etc. also.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89730e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can reference the device: \n",
    "cuda0 = torch.device('cuda:0') \n",
    "#0 corresponds to location of the device. (there could be multiple devices.)\n",
    "\n",
    "# 'cuda' => current device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c52ebb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47408fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1070'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c06d325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set cpu as the device - return device object\n",
    "torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fdf5010",
   "metadata": {},
   "source": [
    "#### specifying device while initilizing tensors\n",
    "if not specified, then its made in CPU   \n",
    "and operations on that will also be done in CPU  \n",
    "\n",
    "create tensor on gpu and return the reference(can assign to a variable)  \n",
    "operations run on them will also run on the gpu.  \n",
    "\n",
    "'device' refers to the GPU and 'host' refers to the CPU  \n",
    "\n",
    "notice the device in the object (in printed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87d57386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "A2 = torch.ones(3,2, device=cuda0) \n",
    "\n",
    "print(A2)\n",
    "\n",
    "B2 = torch.ones(3,2, device=cuda0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fae548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ddeb0cc",
   "metadata": {},
   "source": [
    "#### slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e90bcb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.size()\n",
    "\n",
    "X2[:,1]\n",
    "\n",
    "X2[1,1] #returns as a tensor (here, of one element)\n",
    "\n",
    "X2[1,1].item() #to get as numerical value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d364c7c0",
   "metadata": {},
   "source": [
    "one_element_tensor.item() - returns 'value'  \n",
    "tensor on which its called on should be one-element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bba3b0",
   "metadata": {},
   "source": [
    "#### reshaping (view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92b8fc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6625e-44],\n",
       "        [0.0000e+00],\n",
       "        [1.2933e-34],\n",
       "        [0.0000e+00],\n",
       "        [1.5330e-42],\n",
       "        [0.0000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.view(2,3) # like \"viewing\" in a different dimension.\n",
    "# returns the tensor with specified dimension\n",
    "# can be assigned to another var. (X2 will have orig dim.)\n",
    "# .reshape in numpy also only returns the reshaped.\n",
    "# no in-place\n",
    "\n",
    "X2.view(6,-1) \n",
    "# -1 => the second dimension automatically taken to match the total size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508fc38",
   "metadata": {},
   "source": [
    "mismatch in dimensions of tensor is a main cause of bugs in DL codes.\n",
    "\n",
    "**keep track of dimension of all tensors, etc..  (as comments..)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843a8fd",
   "metadata": {},
   "source": [
    "#### operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45b580de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6625e-44, 0.0000e+00],\n",
       "        [1.2933e-34, 0.0000e+00],\n",
       "        [1.5330e-42, 0.0000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 + Y2 #element wise.\n",
    "\n",
    "X2 - Y2\n",
    "\n",
    "X2.add(Y2) #add and return\n",
    "\n",
    "X2.add_(Y2) #ADDITION IN PLACE. X2 also modified. like X2 += Y2\n",
    "# also returns the result\n",
    "# when we don't want to generate new tensors. save space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6533f3",
   "metadata": {},
   "source": [
    "function names with \"_\" (**underscore**) - in place operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa4640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d05661a",
   "metadata": {},
   "source": [
    "## Numpy <-> Torch (conversion)  \n",
    "\n",
    "**tensor_var.numpy()** - gives ndarray from tensor  \n",
    "\n",
    "**torch.from_numpy( ndarray )** - gives tensor from ndarray (**+they share storage**)    \n",
    "(**Brdige**)\n",
    "\n",
    "\n",
    "\n",
    "**torch.tensor( ndarray )** - gives tensor (**Not Bridge**)   \n",
    "\n",
    "from_numpy() automatically inherits input array dtype. On the other hand, torch.Tensor is an alias for torch.FloatTensor(always gives a float tensor)  \n",
    "also, this works on list as well - use to create a tensor.   \n",
    " \n",
    "tensor => tensor object  \n",
    "ndarray => ndarray object  \n",
    "\n",
    "**TO CONVERT TO NUMPY, TENSOR SHOULD BE IN CPU**\n",
    "- tensor.cpu() - move tensor to cpu\n",
    "\n",
    "\\------------------------------------\n",
    "\n",
    "naming for tensor?  \"tr\"  \n",
    "no such suffix => normal python variable or numpy type  \n",
    "same name - other than the suffix => \"bridge\"   \n",
    "\n",
    "but unnecessary - as everything will be tensors.\n",
    "\n",
    "naming for cpu/gpu ??  \n",
    "\n",
    "prefix??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adce0342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor to np-array\n",
    "\n",
    "torch.ones(3,2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63a7bfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np array to tensor\n",
    "\n",
    "torch.from_numpy( np.array([1,2,3]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca5cbc",
   "metadata": {},
   "source": [
    "### Storage BRIDGE  \n",
    "\n",
    "**T = torch.from_numpy(N)**    \n",
    "\n",
    "Both get changed by operation on one.   \n",
    "They reference the **same memory**   \n",
    "\n",
    "code written for torch, numpy...  \n",
    "with this we can easily transfer stuff...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33b53910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.36252322 1.19878702 1.5066362  1.40123207 1.19256656]\n",
      "tensor([1.3625, 1.1988, 1.5066, 1.4012, 1.1926], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# BRIDGE\n",
    "A = np.random.randn(5)\n",
    "Atr = torch.from_numpy(A) # tensor\n",
    "\n",
    "# operation on ndarray\n",
    "np.add(A,1,out=A) #'out' -> also returns the output\n",
    "\n",
    "print(A)\n",
    "print(Atr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b659c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
