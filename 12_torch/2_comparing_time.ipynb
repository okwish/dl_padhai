{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a6b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77131225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "dev =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97aac5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690973b9",
   "metadata": {},
   "source": [
    "**for all tensors : operation in the same processor(gpu/cpu)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0033b8",
   "metadata": {},
   "source": [
    "### Comparing time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c144c367",
   "metadata": {},
   "source": [
    "#### Addition :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553ae2f",
   "metadata": {},
   "source": [
    "#### CPU, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35aa9b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gks4mAuKL7c",
    "outputId": "83ee8950-95cd-49c1-faec-f3d2a534a3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.9 s, sys: 2 s, total: 40.9 s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    A2 = np.random.randn(10000,10000)\n",
    "    B2 = np.random.randn(10000,10000)\n",
    "    np.add(B2, A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b51ff",
   "metadata": {},
   "source": [
    "#### CPU, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09982f18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMpY0wkCKPL1",
    "outputId": "c02e4ab7-feb7-4881-d119-45c017128f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 1.8 s, total: 16.6 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    A2_cpu = torch.randn([10000, 10000])\n",
    "    B2_cpu = torch.randn([10000, 10000])\n",
    "    B2_cpu.add_(A2_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8932e",
   "metadata": {},
   "source": [
    "#### GPU, torch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21b23df7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1-HuJuJKQY0",
    "outputId": "a09127e3-6a21-48ba-86a6-6f489ff5f1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 543 ms, sys: 277 ms, total: 820 ms\n",
      "Wall time: 832 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    A2_gpu = torch.randn([10000, 10000], device=dev)\n",
    "    B2_gpu = torch.randn([10000, 10000], device=dev)\n",
    "    B2_gpu.add_(A2_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23bacf",
   "metadata": {
    "id": "yMIfo7ujLUUT"
   },
   "source": [
    "tensors in gpu => operation also done on gpu  \n",
    "\n",
    "1000 times improvement going to GPU. very significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edf69a",
   "metadata": {},
   "source": [
    "#### Multiplication :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c738e",
   "metadata": {},
   "source": [
    "#### CPU, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5840621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 611 ms, sys: 682 ms, total: 1.29 s\n",
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    A2 = np.random.randn(100,100)\n",
    "    B2 = np.random.randn(100,100)\n",
    "    C2 = np.matmul(B2, A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79475a9",
   "metadata": {},
   "source": [
    "#### CPU, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8912f63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "vMpeggeiKUtk",
    "outputId": "85b73b52-0618-4c72-e620-a326fb3ebbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 26s, sys: 4.06 s, total: 4min 30s\n",
      "Wall time: 54.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    A2tr_cpu = torch.randn([10000, 10000])\n",
    "    B2tr_cpu = torch.randn([10000, 10000])\n",
    "    C2tr_cpu = torch.matmul(A2tr_cpu, B2tr_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d3b0f",
   "metadata": {},
   "source": [
    "#### GPU, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa994333",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyE49MA1KV6I",
    "outputId": "72a05ca6-3a24-40e6-c8eb-fd486c6009b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 229 ms, sys: 148 ms, total: 377 ms\n",
      "Wall time: 628 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    A2tr_gpu = torch.randn([10000, 10000], device=dev)\n",
    "    B2tr_gpu = torch.randn([10000, 10000], device=dev)\n",
    "    torch.matmul(A2tr_gpu, B2tr_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83db8db",
   "metadata": {
    "id": "EMeYQdi4Lte-"
   },
   "source": [
    "speed up operations like multication are also good as they are parallelisable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b42ff4",
   "metadata": {},
   "source": [
    "pytorch is able to run faster in cpu also. (better cpu optimization also by pytorch, than numpy)\n",
    "\n",
    "there was large imrovement going from normal python to numpy  \n",
    "further speed up going from numpy to pytorch..   \n",
    "even further speedup going from CPUs to GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57984ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
