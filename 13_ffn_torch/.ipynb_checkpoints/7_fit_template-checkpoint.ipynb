{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so far we were accessig a global data, model_obj, optim, loss_fn etc. in fit function. Now we pass all of those to fit function.\n",
    "\n",
    "pass:  \n",
    "- data\n",
    "- model_obj\n",
    "- optim_obj (this need model parameters) \n",
    "- loss function\n",
    "- hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajivlrTGqhXD",
    "outputId": "560ef51d-5085-4ed3-88d2-dd3dc83040bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb35b624d70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0) #torch seed for random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoOS7L2AqsZG",
    "outputId": "1d19d1f2-2d33-4de1-bc27-d83c0e3f10f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 2) (250, 2) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, labels = make_blobs(n_samples=1000, centers=4, n_features=2, random_state=0)\n",
    "\n",
    "XX_train, XX_val, Y_train, Y_val = train_test_split(data, labels, \n",
    "                                                  stratify=labels, random_state=0)\n",
    "print(XX_train.shape, XX_val.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data as torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yF1DDagnt41G",
    "outputId": "1d1af76d-acbe-4f18-aeb2-7cb81566441a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([750, 2]) torch.Size([750])\n"
     ]
    }
   ],
   "source": [
    "XX_train, Y_train, XX_val, Y_val = map(torch.tensor, (XX_train, Y_train, XX_val, Y_val)) \n",
    "\n",
    "# map the function to all and return all. - instead of calling on each one by one.\n",
    "\n",
    "print(XX_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train = XX_train.float()\n",
    "Y_train = Y_train.long()  # as its an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this way of coding with a core **fit function**.  \n",
    "\n",
    "declare model seperately - the can play with hyperparameters,optimizers, etc. in the fit function. Its takes all those stuff as input.  \n",
    "\n",
    "**input to fit -> data, model, optimizer, loss function, hyperparameters**  \n",
    "\n",
    "#### in fit:\n",
    "\n",
    "for each epoch:  \n",
    "\n",
    "&emsp; pred = forward_pass(input) # forward pass  \n",
    "&emsp; loss = loss_fn(pred, ground_truth) # objective function  \n",
    "\n",
    "&emsp; loss.backward() #compute gradient  \n",
    "\n",
    "&emsp; while no-grad:  \n",
    "&emsp;&emsp; opt.step() # update parameters   \n",
    "&emsp;&emsp; opt.zero_grad() # reset gradients   \n",
    "\n",
    "log - loss, accuracy, .. after each epoch.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FIZIKWepU479"
   },
   "outputs": [],
   "source": [
    "# clean fit\n",
    "\n",
    "# (not doing book keeping here)\n",
    "\n",
    "\n",
    "def fit(XX, YY, model_obj, opt, loss_fn, epochs=1000):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # forward and loss\n",
    "        loss = loss_fn( model_obj(XX), YY )\n",
    "        \n",
    "        # computing gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        # updating parameters\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item() # return loss after all epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zL8uy48aEG4S"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 2), \n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(2, 4), \n",
    "            nn.Softmax(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, XX):\n",
    "        return self.net(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = ModelClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZoElzFAVGWv",
    "outputId": "08b20d3f-60cf-4c7f-d258-d3081f7a2921"
   },
   "outputs": [],
   "source": [
    "# defining loss function\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "# defining optimizer\n",
    "opt = optim.SGD(model_obj.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873841404914856"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(XX_train, Y_train, model_obj, opt, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2XrMMNpWHwG"
   },
   "source": [
    "**Step by step abstractions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r07oI4cSHbvE"
   },
   "source": [
    "- nn.Module class  \n",
    "  calling object like a fn calls forward  \n",
    "  - nn.Parameters - wrap all parameters with this - then can iterate over them to update them.\n",
    "  shorthand for updating parameters(don't need specific names), and also setting all gradients to 0 after updating.\n",
    "  - nn.Linear - inbuilt model-class-block  \n",
    "  - nn.Sequential - list of model-blocks sequentially\n",
    "  \n",
    "- optim  \n",
    "  parameters passed. Parameter updation step(iterating over parameters()) atomatically (based on corresponding optimization method)\n",
    "\n",
    "- nn.functional\n",
    "  for loss functions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
